{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "current-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row, SQLContext\n",
    "from pyspark.sql.functions import udf, col, date_format\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.ml.feature import CountVectorizer, CountVectorizerModel, IDF, RegexTokenizer, StopWordsRemover\n",
    "from pyspark.ml.clustering import LDA, LocalLDAModel\n",
    "from pyspark.ml import Pipeline\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set_style(\"whitegrid\")\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "otherwise-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('NLP').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-charles",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bulgarian-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"data/merged_df_final.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "developmental-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['province_state', 'date', 'confirmed_state', 'deaths_state', 'governor_tweet']]\n",
    "df = df.drop_duplicates(subset=['governor_tweet', 'province_state'])\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "private-fighter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+---------------+------------+--------------------------+\n",
      "|province_state|      date|confirmed_state|deaths_state|            governor_tweet|\n",
      "+--------------+----------+---------------+------------+--------------------------+\n",
      "|       Florida|2020/08/31|       623471.0|     11187.0|      (8/8): ED visits ...|\n",
      "|      Illinois|2020/04/26|        43903.0|      1933.0|      4/26 COVID-19 Dai...|\n",
      "|      Delaware|2020/06/03|         9712.0|       375.0|      As businesses reo...|\n",
      "|  North Dakota|2021/01/15|        95599.0|      1395.0|      At 3:00 p.m. we w...|\n",
      "|      Missouri|2020/06/01|        13724.0|       776.0|      Before COVID-19, ...|\n",
      "|        Oregon|2020/04/30|         2510.0|       103.0|COVID-19에 관한 이 자료...|\n",
      "|      Illinois|2020/06/25|       139434.0|      6810.0|      Como resultado, h...|\n",
      "|     Louisiana|2020/08/26|       144960.0|      4851.0|      Despite progress ...|\n",
      "|        Oregon|2020/11/14|        56018.0|       759.0|      During the Two-We...|\n",
      "|       Georgia|2020/08/15|       235168.0|      4669.0|      Georgia continues...|\n",
      "|         Texas|2020/07/26|       394084.0|      5076.0|      Great job Galvest...|\n",
      "|      Colorado|2021/01/30|       395019.0|      5620.0|      I got my first CO...|\n",
      "|      Michigan|2020/06/02|        57731.0|      5553.0|      I will be testify...|\n",
      "|   Connecticut|2020/05/15|        36085.0|      3285.0|      Ill be joined by ...|\n",
      "|      Illinois|2020/12/16|       870600.0|     15777.0|      It’s incumbent up...|\n",
      "|  Rhode Island|2020/04/03|          711.0|        14.0|      I’m proud to anno...|\n",
      "| West Virginia|2020/12/25|        78836.0|      1247.0|      LIVE: Gov. Justic...|\n",
      "|North Carolina|2020/05/14|        16968.0|       641.0|      Phase 1, which st...|\n",
      "|      Missouri|2020/11/12|       229712.0|      3351.0|      Shortly after, I ...|\n",
      "|      Missouri|2020/05/06|         9323.0|       428.0|      Temporary changes...|\n",
      "+--------------+----------+---------------+------------+--------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "animated-arctic",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=df.rdd.map(lambda x: x['governor_tweet'])\n",
    "tweets=texts.zipWithIndex()\n",
    "data = spark.createDataFrame(tweets, [\"tweets\",'index'])\n",
    "\n",
    "removePunct = udf(\n",
    "    lambda s: re.sub(r'[^a-zA-Z0-9]|[0-9]', r' ', s).strip().lower(), T.StringType())\n",
    "\n",
    "# normalize the post content (remove html tags, punctuation and lower case..)\n",
    "data_norm = data.withColumn(\"text\", removePunct(data.tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "formal-camera",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/miao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\",\n",
    "                           gaps=True, pattern=r'\\s+', minTokenLength=2)\n",
    "df_tokens = tokenizer.transform(data_norm)\n",
    "\n",
    "nltk.download('stopwords')#must be downloaded to run\n",
    "stop_words = stopwords.words(\"english\") + [\"which\", \"amp\", \"who\", \"whose\", \"xa\", \"de\", \"http\"]\n",
    "removeStop=udf(lambda word: [x for x in word if x not in stop_words])\n",
    "df_tokens=df_tokens.withColumn('noStopWords',removeStop(df_tokens['words']))\n",
    "\n",
    "label_udf = udf(lambda x: x, T.ArrayType(T.StringType())) \n",
    "df_tokens=df_tokens.withColumn('final_words',label_udf(df_tokens.noStopWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "alien-initial",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tweets: string (nullable = true)\n",
      " |-- index: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- noStopWords: string (nullable = true)\n",
      " |-- final_words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tokens.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "rotary-carter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+-----+--------------------+\n",
      "|                    tweets|index|         final_words|\n",
      "+--------------------------+-----+--------------------+\n",
      "|      (8/8): ED visits ...|    0|[ed, visits, covi...|\n",
      "|      4/26 COVID-19 Dai...|    1|[covid, daily, br...|\n",
      "|      As businesses reo...|    2|[businesses, reop...|\n",
      "|      At 3:00 p.m. we w...|    3|[host, covid, pre...|\n",
      "|      Before COVID-19, ...|    4|[covid, one, prio...|\n",
      "|COVID-19에 관한 이 자료...|    5|[covid, https, co...|\n",
      "|      Como resultado, h...|    6|[como, resultado,...|\n",
      "|      Despite progress ...|    7|[despite, progres...|\n",
      "|      During the Two-We...|    8|[two, week, freez...|\n",
      "|      Georgia continues...|    9|[georgia, continu...|\n",
      "|      Great job Galvest...|   10|[great, job, galv...|\n",
      "|      I got my first CO...|   11|[got, first, covi...|\n",
      "|      I will be testify...|   12|[testifying, subc...|\n",
      "|      Ill be joined by ...|   13|[ill, joined, cvs...|\n",
      "|      It’s incumbent up...|   14|[incumbent, upon,...|\n",
      "|      I’m proud to anno...|   15|[proud, announce,...|\n",
      "|      LIVE: Gov. Justic...|   16|[live, gov, justi...|\n",
      "|      Phase 1, which st...|   17|[phase, still, in...|\n",
      "|      Shortly after, I ...|   18|[shortly, signed,...|\n",
      "|      Temporary changes...|   19|[temporary, chang...|\n",
      "+--------------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tokens[['tweets', 'index', 'final_words']].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-philosophy",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "devoted-enough",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.3 ms, sys: 13.7 ms, total: 47.9 ms\n",
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TF\n",
    "#VocabSize of 20000 words and words with frequencies above 10\n",
    "cv = CountVectorizer(inputCol=\"final_words\", outputCol=\"raw_features\",vocabSize=20000, minDF=10.0)\n",
    "cvmodel = cv.fit(df_tokens)\n",
    "\n",
    "result_cv = cvmodel.transform(df_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "light-highway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.8 ms, sys: 11.1 ms, total: 36.8 ms\n",
      "Wall time: 7.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# IDF\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "idfModel = idf.fit(result_cv)\n",
    "result_tfidf = idfModel.transform(result_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "consistent-consistency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing documents:  8214 2098\n",
      "CPU times: user 945 ms, sys: 446 ms, total: 1.39 s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#split 80% train set and 20% test set\n",
    "df_training, df_testing = result_tfidf.randomSplit([0.8, 0.2], 1)\n",
    "print('Training and testing documents: ', df_training.count(), df_testing.count())\n",
    "\n",
    "num_topics=10\n",
    "max_iterations=50\n",
    "lda = LDA(k=num_topics, maxIter=max_iterations)\n",
    "ldaModel = lda.fit(result_tfidf )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-respect",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "pharmaceutical-detector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------------------------+----------------------------------------+\n",
      "|topic|words                                        |weights                                 |\n",
      "+-----+---------------------------------------------+----------------------------------------+\n",
      "|1    |[testing, get, test, find, sites]            |[0.0242, 0.0126, 0.0108, 0.0096, 0.0095]|\n",
      "|2    |[spread, mask, stay, keep, wear]             |[0.0145, 0.0116, 0.0112, 0.0101, 0.0097]|\n",
      "|3    |[statewide, deaths, cases, additional, new]  |[0.0294, 0.0276, 0.0273, 0.0248, 0.0225]|\n",
      "|4    |[watch, live, briefing, pm, director]        |[0.0260, 0.0206, 0.0203, 0.0190, 0.0148]|\n",
      "|5    |[patients, care, force, hospitals, task]     |[0.0189, 0.0153, 0.0112, 0.0112, 0.0110]|\n",
      "|6    |[businesses, help, small, support, business] |[0.0135, 0.0108, 0.0097, 0.0084, 0.0079]|\n",
      "|7    |[vaccine, doses, care, state, first]         |[0.0124, 0.0087, 0.0083, 0.0072, 0.0068]|\n",
      "|8    |[information, call, response, provides, live]|[0.0185, 0.0177, 0.0168, 0.0164, 0.0160]|\n",
      "|9    |[total, yesterday, positive, tests, data]    |[0.0424, 0.0356, 0.0315, 0.0266, 0.0254]|\n",
      "|10   |[number, icymi, alaska, news, outbreak]      |[0.0203, 0.0125, 0.0105, 0.0094, 0.0091]|\n",
      "+-----+---------------------------------------------+----------------------------------------+\n",
      "\n",
      "Topics: 10 Vocabulary: 2352\n"
     ]
    }
   ],
   "source": [
    "topics = ldaModel.describeTopics(maxTermsPerTopic=5)\n",
    "vocabArray = cvmodel.vocabulary\n",
    "numTopics=10\n",
    "\n",
    "ListOfIndexToWords = udf(lambda wl: list([vocabArray[w] for w in wl]))\n",
    "FormatNumbers = udf(lambda nl: [\"{:1.4f}\".format(x) for x in nl])\n",
    "\n",
    "toptopics = topics.select((topics.topic + 1).alias('topic'),\n",
    "                          ListOfIndexToWords(topics.termIndices).alias('words'),\n",
    "                          FormatNumbers(topics.termWeights).alias('weights'))\n",
    "toptopics.show(truncate=False, n=numTopics)\n",
    "print('Topics:', numTopics, 'Vocabulary:', len(vocabArray))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-possible",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "increasing-controversy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity on testing and training data: 6.69577013712447,6.941993599041921\n"
     ]
    }
   ],
   "source": [
    "lpt, lp = ldaModel.logPerplexity(df_testing), ldaModel.logPerplexity(df_training)\n",
    "print(\"Perplexity on testing and training data: \" + str(lp) + ',' + str(lpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "absolute-default",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood on testing and training data: -986748.4898593953,-3699021.042064962\n"
     ]
    }
   ],
   "source": [
    "llt, ll = ldaModel.logLikelihood(df_testing), ldaModel.logLikelihood(df_training)\n",
    "print(\"Likelihood on testing and training data: \" + str(llt) + ',' + str(ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-smart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference: https://github.com/alejandronotario/LDA-Topic-Modeling/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
