{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Tweets Collection"},{"metadata":{},"cell_type":"markdown","source":"**The following code can be ran in the VM Terminal.**\n\nRequired libraries need to first be downloaded, see https://github.com/cs-ssa-w21/final-project-covid-twitter.\n\nFirst choose directory, and run:\n\n    git clone https://github.com/cs-ssa-w21/final-project-covid-twitter.git\n\nEnter the cloned directory:\n\n    cd ~/final-project-covid-twittera\n\nOpen IPython3 in the Terminal:\n\n    ipython3\n"},{"metadata":{},"cell_type":"markdown","source":"%load_ext autoreload\n%autoreload 2\n%matplotlib inline"},{"metadata":{},"cell_type":"markdown","source":"from covid_data_analysis import *\nfrom scrape_twitter_with_Twint import *"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Collect data from a single Twitter user, and save into JSON file named by the username."},{"metadata":{"trusted":true},"cell_type":"code","source":"name = 'CDCgov'\nget_tweets(username=name, search='COVID', since='2019-07-01', \n           until='2021-05-31', output='data_new//{}_1907_2105.json'.format(name)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nimport pandas as pd\nimport preprocessor as p\nimport nltk\nfrom nltk import word_tokenize, FreqDist\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import TweetTokenizer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read data from JSON file into pandas dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets = []\nfor line in open('data_new/{}_1907_2105.json'.format(filename), 'r', encoding='utf-8'):\n    tweets.append(json.loads(line))\ndf = pd.DataFrame(tweets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df = df[['id', 'date', 'time', 'username', 'tweet', 'hashtags']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clean the tweets"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,v in enumerate(tweets_df['tweet']):\n    p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.SMILEY, p.OPT.MENTION, p.OPT.HASHTAG, p.OPT.RESERVED)\n    tweets_df.loc[i, 'tweet'] = p.clean(v)\n    tweets_df.loc[i, 'tweet'] = tweets_df.loc[i, \"tweet\"]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df['tweet'] = tweets_df['tweet'].str.lower().str.replace('[^\\w\\s]',' ').str.replace('\\s\\s+', ' ')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check the basic information of the cleaned tweets dataframe of a single user."},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df.loc[0:10, 'tweet']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df.loc[:, 'date']","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}