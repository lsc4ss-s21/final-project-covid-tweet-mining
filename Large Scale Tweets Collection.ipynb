{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Large Scale Tweets Collection"},{"metadata":{},"cell_type":"markdown","source":"**The following code can be run on VM Terminal.**\n\nRequired libraries need to first be downloaded, see https://github.com/cs-ssa-w21/final-project-covid-twitter.\n\nManually create a directory for this project, i.e. \"LSC\" on Desktop.\n\nEnter the project directory:\n\n    cd Desktop/LSC/final-project-covid-twitter/\n    \nObtain required environment:\n\n    git clone https://github.com/cs-ssa-w21/final-project-covid-twitter.git\n\nEnter the cloned environment:\n\n    cd ~/final-project-covid-twitter/\n    \nManually create a directory for data storage, i.e. \"data_new\" in data subdirectory."},{"metadata":{},"cell_type":"markdown","source":"**Basic settings for working in IPython3**\n\nOpen IPython3 in the Terminal:\n\n    ipython3\n    \nPreparations:\n\n    %load_ext autoreload\n    %autoreload 2\n    %matplotlib inline"},{"metadata":{},"cell_type":"markdown","source":"**Import required libraries**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from covid_data_analysis import *\nfrom scrape_twitter_with_Twint import *\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\n\nimport json\nimport preprocessor as p\nimport nltk\nfrom nltk import word_tokenize, FreqDist\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import TweetTokenizer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Help functions"},{"metadata":{},"cell_type":"markdown","source":"Read JSON file into pandas DataFrame."},{"metadata":{"trusted":true},"cell_type":"code","source":"def json_to_df(username):\n    tweets = []\n    for line in open('data/data_new/{}.json'.format(username), 'r', encoding='utf-8'):\n        tweets.append(json.loads(line))\n    return pd.DataFrame(tweets)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clean a single twitter dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_df(username):\n    df = json_to_df(username)\n    tweets_df = df[['id', 'date', 'time', 'username', 'tweet', 'hashtags']]\n\n    for i,v in enumerate(tweets_df['tweet']):\n        p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.SMILEY, p.OPT.MENTION, p.OPT.HASHTAG, p.OPT.RESERVED)\n        tweets_df.loc[i, 'tweet'] = p.clean(v)\n        tweets_df.loc[i, 'tweet'] = tweets_df.loc[i, \"tweet\"]\n\n    tweets_df['tweet'] = tweets_df['tweet'].str.lower().str.replace('[^\\w\\s]',' ').str.replace('\\s\\s+', ' ')\n    return tweets_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Collect, store, read and clean tweets for CDCgov"},{"metadata":{},"cell_type":"markdown","source":"Collect tweets from a single user \"CDCgov\", and store into a JSON file."},{"metadata":{"trusted":true},"cell_type":"code","source":"name = 'CDCgov'\nget_tweets(username=name, search='COVID', since='2019-07-01', \n           until='2021-05-31', output='data_new//{}_1907_2105.json'.format(name)) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read data from JSON file into pandas dataframe, and clean the \"CDCgov\" tweets dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df = clean_df(username)\ntweets_df.loc[:, 'date']   # check updates and number of tweets","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check basic information of the cleaned tweets dataframe of \"CDCgov\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df.loc[0:10, 'tweet']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Collect, store, read and clean tweets for 52 States governors"},{"metadata":{"trusted":true},"cell_type":"code","source":"governor = pd.read_csv('data//governor-twitter-handle.csv')\ngovernor.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Collect tweets from 52 States governors, and store into 52 JSON files seperately."},{"metadata":{"trusted":true},"cell_type":"code","source":"k=len(governor) # for convenience of manual test\nget_tweets_from_multiple_users(governor[:k], folder='data_new', search='COVID', since=None, until=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read data from 52 States tweets JSON files into 52 pandas dataframes, clean each dataframe, and make a dictionary of the cleaned dataframes."},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df = {}\nfor i in range(k):\n    username = governor.iloc[i].State\n    tweets_df[username] = clean_df(username)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check basic information of any cleaned State tweets dataframe by searching the \"username\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df[username].loc[:, 'date']   # check updates and number of tweets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df[username].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df[username].loc[0:10, 'tweet']","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}