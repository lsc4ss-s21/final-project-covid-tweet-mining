# final-project-covid-tweet-mining
final-project-covid-tweet-mining created by GitHub Classroom

**Social science research problem:**
2020 is all about Covid-19. This unprecedented global pandemic has changed everyone's daily normal. We have seen that, in the United States, many governors like Andrew Cuomo of New York State published COVID-related content such as policy guidelines on Twitter. In this project, we are going to explore the political communications of state leaders as well as the CDC on Twitter during the pandemic, and how it would be related to the changes in the number of COVID infected cases and deaths. The bulk of the project would be a content analysis of collected tweets.

**Role of Large-scale computing methods:**
We will collect tweets from state governors and the CDC over the period of COVID-19 pandemic, and conduct content analysis (e.g., topic modeling) and visualization (e.g., word cloud). The project will benefit from large-scale computing methods from three perspectives. First, parallel solutions of the Twitter scraping process are expected to significantly improve the efficiency of data collection. With large amounts of textual data, we may also parallelize the preprocessing part (e.g. Tokenization, Stemming, and Lemmatization) and thus accelerate the data cleaning process. Finally, the high performance of large-scale methods enables us to further expand the topic with a larger scale of input data and more tuning and tests on model performance.

**Division of work & Timeline:**
Collect Data (Week8): Fengyi
Preprocess (Week8): Boya
Content Analysis (Week9): Boya, Yile
Visualization (Week9): Yile
Presentation and report rewriting (Week10): Fengyi, Boya, Yile

